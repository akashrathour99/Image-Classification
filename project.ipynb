{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "mount_file_id": "1MiscAdQSWt7L7ms4qgqYH34uCS8J4crO",
      "authorship_tag": "ABX9TyMKGYe5N0CFUiIQXTm7zRFs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashrathour99/Image-Classification/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9b2GYtRadyy"
      },
      "outputs": [],
      "source": [
        "!pip install unrar\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzar the file imported from the google drive\n",
        "!unrar x \"/content/drive/MyDrive/afinal_project /Scanned.rar\""
      ],
      "metadata": {
        "id": "U-fS--bqa9Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x \"/content/drive/MyDrive/afinal_project /Foot_print.rar\""
      ],
      "metadata": {
        "id": "ihauJVHIcMYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NbchhpYYcV-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#some dependecies for model \n",
        "from skimage.io import imread, imshow\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "#these  2 helps in rotaing the image without loosing the data\n",
        "import argparse\n",
        "import imutils\n"
      ],
      "metadata": {
        "id": "m8UZtIngcWA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##theis the code for image enhencement which leads to more data loss but when we have dectyloscopic type data then this will work fine \n",
        "left_dir=\"Scanned\"\n",
        "# getting the names of the data for furthur process\n",
        "left_items = sorted([x for x in os.listdir(left_dir) if x.endswith(\".jpg\")], key=lambda x: (x.split(\".\")[0]))\n",
        "for imgg in left_items:\n",
        "  black = (0,0,0)\n",
        "  white = (255,255,255)\n",
        "  threshold = (160,160,160)\n",
        "  img = Image.open(\"Scanned\"+\"/\"+imgg).convert(\"LA\")\n",
        "  pixels = img.getdata()\n",
        "  newPixels = []\n",
        "  for pixel in pixels:\n",
        "      if pixel < threshold:\n",
        "          newPixels.append(black)\n",
        "      else:\n",
        "          newPixels.append(white)\n",
        "  newImg = Image.new(\"RGB\",img.size)\n",
        "  newImg.putdata(newPixels)\n",
        "  #saving the data or rewriting the same image after enhencement\n",
        "  newImg.save(\"Scanned\"+\"/\"+imgg)"
      ],
      "metadata": {
        "id": "RnXVCql_mFpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this functio gonna help me to get the name of the person for ordering the data to the right file\n",
        "def check(img):\n",
        "  ans=\"\"\n",
        "  ans=img[0]\n",
        "  if(ord(img[1])-48>=0 and ord(img[1])-48<=9):\n",
        "    ans+=img[1]\n",
        "  return ans"
      ],
      "metadata": {
        "id": "XKucI1wSo3fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function gonna help for rotating the images or creating more data for traing\n",
        "#and saving the data to the write folder\n",
        "# the data will be splited in 25% for testing\n",
        "def rot(img,image):\n",
        "  t=1\n",
        "  for angle in np.arange(0, 360, 30):\n",
        "    rotated = imutils.rotate_bound(image, angle)\n",
        "    #this line for storing data for training data\n",
        "    path=\"Foot_print/training_data/person\"+check(img)+\"/\"+str(t)+\"_\"+img\n",
        "    cv2.imwrite(path,rotated)\n",
        "    #this code is for generating testing data\n",
        "    if(t%4==0):\n",
        "      path=\"Foot_print/test_data/person\"+check(img)+\"/\"+str(t)+\"_\"+img\n",
        "      cv2.imwrite(path,rotated)\n",
        "    \n",
        "    t=t+1\n"
      ],
      "metadata": {
        "id": "oiZxOXo9pGoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this code gonna help in spliting the scanned data to left and right foot and also changing the data to gray scale\n",
        "\n",
        "\n",
        "left_dir=\"Scanned\"\n",
        "left_items = sorted([x for x in os.listdir(left_dir) if x.endswith(\".jpg\")], key=lambda x: (x.split(\".\")[0]))\n",
        "for img in left_items:\n",
        "  image = imread(\"Scanned\"+\"/\"+img,as_gray=True)\n",
        "  ## this is the gray scale formula\n",
        "  ## imgGray = 0.2989 * R + 0.5870 * G + 0.1140 * B \n",
        "  h, w,= image.shape\n",
        "  half = w//2\n",
        "  # left foot image\n",
        "  left_part = image[:, :half]    \n",
        "  #right foot image       \n",
        "  right_part = image[:, half:]\n",
        "  # called the rotate function for rotaing the images at specified angle\n",
        "  rot(img[:2]+\"-0-\"+img[2:],left_part)\n",
        "  rot(img[:2]+\"-1-\"+img[2:],right_part)"
      ],
      "metadata": {
        "id": "CzhhPwnZcMyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "38oBr3o8ckDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying the folder where images are present\n",
        "TrainingImagePath='Foot_print/training_data'\n",
        " \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True)\n",
        " \n",
        "test_datagen = ImageDataGenerator()\n",
        " \n",
        "# Generating the Training Data\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        TrainingImagePath,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        " \n",
        " \n",
        "# Generating the Testing Data\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        TrainingImagePath,\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        " \n",
        "# Printing class labels for each face\n",
        "test_set.class_indices"
      ],
      "metadata": {
        "id": "5W9G815EckK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "TrainClasses=training_set.class_indices\n",
        "\n",
        "\n",
        "ResultMap={}\n",
        "for faceValue,faceName in zip(TrainClasses.values(),TrainClasses.keys()):\n",
        "    ResultMap[faceValue]=faceName\n",
        "\n",
        "# Saving the footprint map for future reference\n",
        "import pickle\n",
        "with open(\"ResultsMap.pkl\", 'wb') as fileWriteStream:\n",
        "    pickle.dump(ResultMap, fileWriteStream)\n",
        "\n",
        "# The model will give answer as a numeric tag\n",
        "# This mapping will help to get the corresponding face name for it\n",
        "print(\"Mapping of Footprint and its ID\",ResultMap)\n",
        "\n",
        "# The number of neurons for the output layer is equal to the number of faces\n",
        "OutputNeurons=len(ResultMap)\n",
        "print('\\n The Number of output neurons: ', OutputNeurons)"
      ],
      "metadata": {
        "id": "oYzxaQwAckOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "'''Initializing the Convolutional Neural Network'''\n",
        "classifier= Sequential()\n",
        "\n",
        "''' STEP--1 Convolution\n",
        "# Adding the first layer of CNN\n",
        "# we are using the format (64,64,3) because we are using TensorFlow backend\n",
        "# It means 3 matrix of size (64X64) pixels representing Red, Green and Blue components of pixels\n",
        "'''\n",
        "classifier.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n",
        "\n",
        "'''# STEP--2 MAX Pooling'''\n",
        "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "'''############## ADDITIONAL LAYER of CONVOLUTION for better accuracy #################'''\n",
        "classifier.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
        "\n",
        "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "'''# STEP--3 FLattening'''\n",
        "classifier.add(Flatten())\n",
        "\n",
        "'''# STEP--4 Fully Connected Neural Network'''\n",
        "classifier.add(Dense(64, activation='relu'))\n",
        "\n",
        "classifier.add(Dense(OutputNeurons, activation='softmax'))\n",
        "\n",
        "'''# Compiling the CNN'''\n",
        "#classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
        "\n",
        "###########################################################\n",
        "import time\n",
        "# Measuring the time taken by the model to train\n",
        "StartTime=time.time()\n",
        "\n",
        "# Starting the model training\n",
        "classifier.fit_generator(\n",
        "                    training_set,\n",
        "                    steps_per_epoch=len(training_set),\n",
        "                    epochs=35,\n",
        "                    validation_data=test_set,\n",
        "                    validation_steps=len(test_set))\n",
        "\n",
        "EndTime=time.time()\n",
        "print(\"###### Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes ######')"
      ],
      "metadata": {
        "id": "E5WGPTr0ckZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "ImagePath='/content/Foot_print/test_data/person8/4_8--0-4.jpg'\n",
        "test_image=image.load_img(ImagePath,target_size=(64, 64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "\n",
        "result=classifier.predict(test_image,verbose=0)\n",
        "#print(training_set.class_indices)\n",
        "\n",
        "print('####'*10)\n",
        "print('Prediction is: ',ResultMap[np.argmax(result)])"
      ],
      "metadata": {
        "id": "-TZoVmjWeTYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd318d93-2ab9-418b-d86d-78e16e064559"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########################################\n",
            "Prediction is:  person8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ibg65ifAj2P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "jSexJ2t3lQiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2e9y2Sl7lQls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E99GmLJ6lQpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5_rwJd0hlQsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}